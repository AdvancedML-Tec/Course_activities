{
 "cells": [
  {
   "attachments": {
    "638ee97d-a9d5-4e95-aa9f-1ea2bb006236.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAADPCAYAAABfn/UYAAAAAXNSR0IArs4c6QAAAARnQU1BAACx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\nDg4ODtMGnvf/AcRfxR3dKXpTAAAAAElFTkSuQmCC\n"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LogoTec.png](attachment:638ee97d-a9d5-4e95-aa9f-1ea2bb006236.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TC 5033\n",
    "## Deep Learning\n",
    "## Fully Connected Deep Neural Networks\n",
    "## José Antonio Cantoral Ceballos, Ph.D.\n",
    "## Team Members:\n",
    "- A01200230 - Armando Bringas Corpus\n",
    "\n",
    "#### Activity 1b: Implementing a Fully Connected Network for Kaggle ASL Dataset\n",
    "\n",
    "- Objective\n",
    "\n",
    "The aim of this part of the activity is to apply your understanding of Fully Connected Networks by implementing a multilayer network for the [Kaggle ASL (American Sign Language) dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet). While you have been provided with a complete solution for a Fully Connected Network using Numpy for the MNIST dataset, you are encouraged to try to come up with the solution.\n",
    "\n",
    "- Instructions\n",
    "\n",
    "    This activity requires submission in teams of 3 or 4 members. Submissions from smaller or larger teams will not be accepted unless prior approval has been granted (only due to exceptional circumstances). While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
    "\n",
    "    Load and Preprocess Data: You are provided a starter code to load the data. Be sure to understand the code.\n",
    "\n",
    "    Review MNIST Notebook (Optional): Before diving into this activity, you have the option to revisit the MNIST example to refresh your understanding of how to build a Fully Connected Network using Numpy.\n",
    "\n",
    "    Start Fresh: Although you can refer to the MNIST solution at any point, try to implement the network for the ASL dataset on your own. This will reinforce your learning and understanding of the architecture and mathematics involved.\n",
    "\n",
    "    Implement Forward and Backward Pass: Write the code to perform the forward and backward passes, keeping in mind the specific challenges and characteristics of the ASL dataset.\n",
    "    \n",
    "     Design the Network: Create the architecture of the Fully Connected Network tailored for the ASL dataset. Choose the number of hidden layers, neurons, and hyperparameters judiciously.\n",
    "\n",
    "    Train the Model: Execute the training loop, ensuring to track performance metrics such as loss and accuracy.\n",
    "\n",
    "    Analyze and Document: Use Markdown cells to document in detail the choices you made in terms of architecture and hyperparameters, you may use figures, equations, etc to aid in your explanations. Include any metrics that help justify these choices and discuss the model's performance.  \n",
    "\n",
    "- Evaluation Criteria\n",
    "\n",
    "    - Code Readability and Comments\n",
    "    - Appropriateness of chosen architecture and hyperparameters for the ASL dataset\n",
    "    - Performance of the model on the ASL dataset (at least 70% acc)\n",
    "    - Quality of Markdown documentation\n",
    "\n",
    "- Submission\n",
    "\n",
    "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#################################\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/asl_data/'\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
    "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     12     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_df['label'])\n",
    "y_val = np.array(valid_df['label'])\n",
    "del train_df['label']\n",
    "del valid_df['label']\n",
    "x_train = train_df.values.astype(np.float32)\n",
    "x_val = valid_df.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
    "    '''\n",
    "    Create a function that will allow you to split the previously loaded validation set\n",
    "    into validation and test.\n",
    "    '''\n",
    "    # verify that x_val and y_val have the same length\n",
    "    assert len(x) == len(y)\n",
    "\n",
    "    # total of data\n",
    "    total_data = len(x)\n",
    "\n",
    "    # shuffle data if it is required\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(x))\n",
    "        np.random.shuffle(indices)\n",
    "        x, y = map(lambda data: np.array([data[i] for i in indices]), [x, y])\n",
    "\n",
    "    # calculate split index\n",
    "    split_idx = int(pct * len(x))\n",
    "    \n",
    "    return x[:split_idx], y[:split_idx].reshape(-1,1), x[split_idx:], y[split_idx:].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect shape of the splitted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 784)\n",
      "(27455,)\n",
      "(3586, 784)\n",
      "(3586, 1)\n",
      "(3586, 784)\n",
      "(3586, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "### The following\n",
    "\n",
    "alphabet=list(string.ascii_lowercase)\n",
    "alphabet.remove('j')\n",
    "alphabet.remove('z')\n",
    "print(len(alphabet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda function that applies feature scaling to the dataset x_data using the mean x_mean and standard deviation x_std. Feature scaling is a method used to standardize the range of independent variables or features of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise = lambda x_mean, x_std, x_data: (x_data - x_mean) / x_std\n",
    "\n",
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.6268384e-06, 0.99999946)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sampled image represents a: w\n"
     ]
    }
   ],
   "source": [
    "rnd_idx = np.random.randint(len(y_test))\n",
    "image_data = x_test[rnd_idx].reshape(28, 28)\n",
    "plot_number(image_data)\n",
    "\n",
    "print(f'The sampled image represents a: {alphabet[y_test[rnd_idx][0]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equations for Arquitecture and Loss Function of a ReLU-Activated Neural Network Model\n",
    "\n",
    "\n",
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create training minibatches\n",
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    # Shuffle the dataset if the shuffle parameter is True\n",
    "    if shuffle:\n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        # Shuffled indices to reorder the input features and labels\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "    # Generate minibatches\n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear, ReLU and Sequential classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class np_tensor(np.ndarray): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Linear class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        '''\n",
    "        Init parameters utilizando Kaiming He\n",
    "        '''\n",
    "        # Initialize the weights using Kaiming He initialization for better performance with the ReLU activations\n",
    "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor)\n",
    "        # Initialize biases with zeros\n",
    "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
    "    def __call__(self, X):\n",
    "        # Forward pass linear transformation\n",
    "        Z = self.W @ X + self.b\n",
    "        return Z\n",
    "    def backward(self, X, Z):\n",
    "        # Get the gradient with respect to the input\n",
    "        X.grad = self.W.T @ Z.grad\n",
    "        # Get the gradient with respect to the weights\n",
    "        self.W.grad = Z.grad @ X.T\n",
    "        # Get the gradient with respect to the biases\n",
    "        self.b.grad = np.sum(Z.grad, axis = 1, keepdims=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __call__(self, Z):\n",
    "        # ReLU activation that replaces negative values in Z with 0\n",
    "        return np.maximum(0, Z)\n",
    "    def backward(self, Z, A):\n",
    "        # Copy the gradient from the next layer\n",
    "        Z.grad = A.grad.copy()\n",
    "        # Zero the gradient where the function is not activated\n",
    "        Z.grad[Z <= 0] = 0\n",
    "        Z.grad[Z <= 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential_layers():\n",
    "    def __init__(self, layers):\n",
    "        '''\n",
    "        layers - lista que contiene objetos de tipo Linear, ReLU\n",
    "        '''\n",
    "        self.layers = layers\n",
    "        self.x = None\n",
    "        self.outputs = {}\n",
    "    def __call__(self, X):\n",
    "        self.x = X \n",
    "        self.outputs['l0'] = self.x\n",
    "        # Forward pass through each layer\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            self.x = layer(self.x)\n",
    "            self.outputs['l'+str(i)]=self.x\n",
    "        # Return the output for backpropagation\n",
    "        return self.x\n",
    "    def backward(self):\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])\n",
    "    def update(self, learning_rate = 1e-3):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, ReLU): continue\n",
    "            # Update weights and biases with gradient descent\n",
    "            layer.W = layer.W - learning_rate * layer.W.grad\n",
    "            layer.b = layer.b - learning_rate * layer.b.grad\n",
    "    def predict(self, X):\n",
    "        # Forward pass and return the index of the max value\n",
    "        return np.argmax(self.__call__(X)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmaxXEntropy(x, y):\n",
    "    batch_size = x.shape[1]\n",
    "    \n",
    "    # Compute the exponential scores for numerical stability in softmax\n",
    "    # Compute the probabilities for each class by normalizing the exponential scores\n",
    "    exp_scores = np.exp(x)\n",
    "    probs = exp_scores / exp_scores.sum(axis = 0)\n",
    "    preds = probs.copy()\n",
    "    \n",
    "    # Compute the cross-entropy cost\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
    "    \n",
    "    # Calculate gradients for backpropagation\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1 #dl/dx\n",
    "    x.grad = probs.copy()\n",
    "    \n",
    "    return preds, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for training the model\n",
    "def train(model, epochs, mb_size=128, learning_rate = 1e-3):\n",
    "    # Iterate over each epoch\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
    "            # Perform a forward pass and compute score\n",
    "            scores = model(x.T.view(np_tensor))\n",
    "            # Calculate the cost and gradients with respect score\n",
    "            _, cost = softmaxXEntropy(scores, y)\n",
    "            # Perform backward pass and then update learning rate\n",
    "            model.backward()\n",
    "            model.update(learning_rate)\n",
    "\n",
    "        print(f'epochs: {epoch+1}\\t cost: {cost:.4f} \\t accuracy: {accuracy(x_val, y_val, mb_size, model):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the model accuracy\n",
    "def accuracy(x, y, mb_size, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Iterate over dataset in minibatches\n",
    "    for i, (x, y) in enumerate(create_minibatches(mb_size, x, y)):\n",
    "        # Perform forward pass to get predictions from the model\n",
    "        pred = model(x.T.view(np_tensor))\n",
    "        # Count how many predictions match with the true labels and get the total\n",
    "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze())\n",
    "        total += pred.shape[1]\n",
    "        \n",
    "    # Handle the case where total is zero to avoid division by zero\n",
    "    if total == 0:\n",
    "        return 0  # or return an appropriate value or message indicating no data was processed\n",
    "    \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your model and train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "BATCH_SIZE = 512\n",
    "INPUT_DIM = x_train.shape[1]\n",
    "OUTPUT_DIM = len(alphabet)\n",
    "NEURONS = [300, 500, 700]\n",
    "LEARNING_RATES = [1e-3, 5e-4, 1e-4]\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Architecture:\n",
    "\n",
    "Input -> Linear -> ReLU -> Linear -> ReLU -> Linear -> ReLU -> Linear -> Output\n",
    "\n",
    "This type of architecture is common in feedforward neural networks, where the goal is to transform the input data through successive layers of computation to make a prediction. ReLU activation functions are used to help combat the vanishing gradient problem, which allows the network to learn faster and perform better on a variety of tasks.\n",
    "\n",
    "The intention is to test with different combinations of model hyperparameters to determine which performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Training with Neurons: 300, Learning Rate: 0.001\n",
      "------------------------------------------------------------\n",
      "epochs: 1\t cost: 0.2982 \t accuracy: 0.7214\n",
      "epochs: 2\t cost: 0.0145 \t accuracy: 0.7705\n",
      "epochs: 3\t cost: 0.0050 \t accuracy: 0.7889\n",
      "epochs: 4\t cost: 0.0041 \t accuracy: 0.7875\n",
      "epochs: 5\t cost: 0.0022 \t accuracy: 0.7922\n",
      "epochs: 6\t cost: 0.0015 \t accuracy: 0.7922\n",
      "epochs: 7\t cost: 0.0013 \t accuracy: 0.7895\n",
      "epochs: 8\t cost: 0.0013 \t accuracy: 0.7920\n",
      "epochs: 9\t cost: 0.0011 \t accuracy: 0.7945\n",
      "epochs: 10\t cost: 0.0012 \t accuracy: 0.7936\n",
      "epochs: 11\t cost: 0.0008 \t accuracy: 0.7942\n",
      "epochs: 12\t cost: 0.0006 \t accuracy: 0.7953\n",
      "epochs: 13\t cost: 0.0006 \t accuracy: 0.7956\n",
      "epochs: 14\t cost: 0.0006 \t accuracy: 0.7956\n",
      "epochs: 15\t cost: 0.0005 \t accuracy: 0.7953\n",
      "epochs: 16\t cost: 0.0005 \t accuracy: 0.7959\n",
      "epochs: 17\t cost: 0.0004 \t accuracy: 0.7959\n",
      "epochs: 18\t cost: 0.0005 \t accuracy: 0.7956\n",
      "epochs: 19\t cost: 0.0004 \t accuracy: 0.7945\n",
      "epochs: 20\t cost: 0.0003 \t accuracy: 0.7959\n",
      "\n",
      "Accuracy: 0.8045\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training with Neurons: 500, Learning Rate: 0.001\n",
      "------------------------------------------------------------\n",
      "epochs: 1\t cost: 0.4810 \t accuracy: 0.6849\n",
      "epochs: 2\t cost: 0.0671 \t accuracy: 0.7741\n",
      "epochs: 3\t cost: 0.0092 \t accuracy: 0.7822\n",
      "epochs: 4\t cost: 0.0039 \t accuracy: 0.7847\n",
      "epochs: 5\t cost: 0.0029 \t accuracy: 0.7856\n",
      "epochs: 6\t cost: 0.0016 \t accuracy: 0.7847\n",
      "epochs: 7\t cost: 0.0013 \t accuracy: 0.7869\n",
      "epochs: 8\t cost: 0.0013 \t accuracy: 0.7867\n",
      "epochs: 9\t cost: 0.0010 \t accuracy: 0.7864\n",
      "epochs: 10\t cost: 0.0006 \t accuracy: 0.7858\n",
      "epochs: 11\t cost: 0.0006 \t accuracy: 0.7853\n",
      "epochs: 12\t cost: 0.0007 \t accuracy: 0.7853\n",
      "epochs: 13\t cost: 0.0006 \t accuracy: 0.7858\n",
      "epochs: 14\t cost: 0.0006 \t accuracy: 0.7867\n",
      "epochs: 15\t cost: 0.0005 \t accuracy: 0.7864\n",
      "epochs: 16\t cost: 0.0004 \t accuracy: 0.7875\n",
      "epochs: 17\t cost: 0.0004 \t accuracy: 0.7878\n",
      "epochs: 18\t cost: 0.0004 \t accuracy: 0.7867\n",
      "epochs: 19\t cost: 0.0004 \t accuracy: 0.7878\n",
      "epochs: 20\t cost: 0.0004 \t accuracy: 0.7878\n",
      "\n",
      "Accuracy: 0.8067\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training with Neurons: 700, Learning Rate: 0.001\n",
      "------------------------------------------------------------\n",
      "epochs: 1\t cost: 0.7115 \t accuracy: 0.7094\n",
      "epochs: 2\t cost: 0.0135 \t accuracy: 0.7727\n",
      "epochs: 3\t cost: 0.0055 \t accuracy: 0.7727\n",
      "epochs: 4\t cost: 0.0031 \t accuracy: 0.7780\n",
      "epochs: 5\t cost: 0.0022 \t accuracy: 0.7780\n",
      "epochs: 6\t cost: 0.0014 \t accuracy: 0.7783\n",
      "epochs: 7\t cost: 0.0013 \t accuracy: 0.7794\n",
      "epochs: 8\t cost: 0.0009 \t accuracy: 0.7800\n",
      "epochs: 9\t cost: 0.0012 \t accuracy: 0.7803\n",
      "epochs: 10\t cost: 0.0009 \t accuracy: 0.7811\n",
      "epochs: 11\t cost: 0.0008 \t accuracy: 0.7814\n",
      "epochs: 12\t cost: 0.0006 \t accuracy: 0.7814\n",
      "epochs: 13\t cost: 0.0007 \t accuracy: 0.7814\n",
      "epochs: 14\t cost: 0.0006 \t accuracy: 0.7814\n",
      "epochs: 15\t cost: 0.0004 \t accuracy: 0.7817\n",
      "epochs: 16\t cost: 0.0005 \t accuracy: 0.7814\n",
      "epochs: 17\t cost: 0.0007 \t accuracy: 0.7817\n",
      "epochs: 18\t cost: 0.0004 \t accuracy: 0.7817\n",
      "epochs: 19\t cost: 0.0003 \t accuracy: 0.7819\n",
      "epochs: 20\t cost: 0.0003 \t accuracy: 0.7814\n",
      "\n",
      "Accuracy: 0.7962\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training with Neurons: 300, Learning Rate: 0.0005\n",
      "------------------------------------------------------------\n",
      "epochs: 1\t cost: 0.2447 \t accuracy: 0.7724\n",
      "epochs: 2\t cost: 0.0252 \t accuracy: 0.7998\n",
      "epochs: 3\t cost: 0.0114 \t accuracy: 0.8026\n",
      "epochs: 4\t cost: 0.0073 \t accuracy: 0.8093\n",
      "epochs: 5\t cost: 0.0058 \t accuracy: 0.8109\n",
      "epochs: 6\t cost: 0.0048 \t accuracy: 0.8132\n",
      "epochs: 7\t cost: 0.0034 \t accuracy: 0.8146\n",
      "epochs: 8\t cost: 0.0026 \t accuracy: 0.8143\n",
      "epochs: 9\t cost: 0.0025 \t accuracy: 0.8143\n",
      "epochs: 10\t cost: 0.0019 \t accuracy: 0.8176\n",
      "epochs: 11\t cost: 0.0017 \t accuracy: 0.8171\n",
      "epochs: 12\t cost: 0.0016 \t accuracy: 0.8176\n",
      "epochs: 13\t cost: 0.0015 \t accuracy: 0.8171\n",
      "epochs: 14\t cost: 0.0017 \t accuracy: 0.8187\n",
      "epochs: 15\t cost: 0.0014 \t accuracy: 0.8193\n",
      "epochs: 16\t cost: 0.0011 \t accuracy: 0.8187\n",
      "epochs: 17\t cost: 0.0009 \t accuracy: 0.8185\n",
      "epochs: 18\t cost: 0.0012 \t accuracy: 0.8173\n",
      "epochs: 19\t cost: 0.0009 \t accuracy: 0.8196\n",
      "epochs: 20\t cost: 0.0008 \t accuracy: 0.8199\n",
      "\n",
      "Accuracy: 0.8224\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training with Neurons: 500, Learning Rate: 0.0005\n",
      "------------------------------------------------------------\n",
      "epochs: 1\t cost: 0.1366 \t accuracy: 0.7504\n",
      "epochs: 2\t cost: 0.0171 \t accuracy: 0.7649\n",
      "epochs: 3\t cost: 0.0111 \t accuracy: 0.7638\n",
      "epochs: 4\t cost: 0.0065 \t accuracy: 0.7733\n",
      "epochs: 5\t cost: 0.0046 \t accuracy: 0.7683\n",
      "epochs: 6\t cost: 0.0044 \t accuracy: 0.7786\n",
      "epochs: 7\t cost: 0.0032 \t accuracy: 0.7775\n",
      "epochs: 8\t cost: 0.0030 \t accuracy: 0.7794\n",
      "epochs: 9\t cost: 0.0024 \t accuracy: 0.7811\n",
      "epochs: 10\t cost: 0.0021 \t accuracy: 0.7836\n",
      "epochs: 11\t cost: 0.0016 \t accuracy: 0.7805\n",
      "epochs: 12\t cost: 0.0013 \t accuracy: 0.7825\n",
      "epochs: 13\t cost: 0.0014 \t accuracy: 0.7858\n",
      "epochs: 14\t cost: 0.0011 \t accuracy: 0.7875\n",
      "epochs: 15\t cost: 0.0012 \t accuracy: 0.7872\n",
      "epochs: 16\t cost: 0.0012 \t accuracy: 0.7878\n",
      "epochs: 17\t cost: 0.0010 \t accuracy: 0.7883\n",
      "epochs: 18\t cost: 0.0011 \t accuracy: 0.7897\n",
      "epochs: 19\t cost: 0.0009 \t accuracy: 0.7878\n",
      "epochs: 20\t cost: 0.0009 \t accuracy: 0.7895\n",
      "\n",
      "Accuracy: 0.7975\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training with Neurons: 700, Learning Rate: 0.0005\n",
      "------------------------------------------------------------\n",
      "epochs: 1\t cost: 0.1377 \t accuracy: 0.7323\n",
      "epochs: 2\t cost: 0.0222 \t accuracy: 0.7699\n",
      "epochs: 3\t cost: 0.0108 \t accuracy: 0.7833\n",
      "epochs: 4\t cost: 0.0074 \t accuracy: 0.7867\n",
      "epochs: 5\t cost: 0.0044 \t accuracy: 0.7917\n",
      "epochs: 6\t cost: 0.0039 \t accuracy: 0.7889\n",
      "epochs: 7\t cost: 0.0034 \t accuracy: 0.7903\n",
      "epochs: 8\t cost: 0.0024 \t accuracy: 0.7869\n",
      "epochs: 9\t cost: 0.0022 \t accuracy: 0.7934\n",
      "epochs: 10\t cost: 0.0016 \t accuracy: 0.7925\n",
      "epochs: 11\t cost: 0.0018 \t accuracy: 0.7925\n",
      "epochs: 12\t cost: 0.0015 \t accuracy: 0.7928\n",
      "epochs: 13\t cost: 0.0014 \t accuracy: 0.7934\n",
      "epochs: 14\t cost: 0.0013 \t accuracy: 0.7934\n",
      "epochs: 15\t cost: 0.0011 \t accuracy: 0.7962\n",
      "epochs: 16\t cost: 0.0011 \t accuracy: 0.7948\n",
      "epochs: 17\t cost: 0.0009 \t accuracy: 0.7942\n",
      "epochs: 18\t cost: 0.0010 \t accuracy: 0.7948\n",
      "epochs: 19\t cost: 0.0008 \t accuracy: 0.7934\n",
      "epochs: 20\t cost: 0.0007 \t accuracy: 0.7962\n",
      "\n",
      "Accuracy: 0.7987\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training with Neurons: 300, Learning Rate: 0.0001\n",
      "------------------------------------------------------------\n",
      "epochs: 1\t cost: 0.8526 \t accuracy: 0.5945\n",
      "epochs: 2\t cost: 0.3229 \t accuracy: 0.6949\n",
      "epochs: 3\t cost: 0.1706 \t accuracy: 0.7170\n",
      "epochs: 4\t cost: 0.0836 \t accuracy: 0.7379\n",
      "epochs: 5\t cost: 0.0576 \t accuracy: 0.7443\n",
      "epochs: 6\t cost: 0.0407 \t accuracy: 0.7485\n",
      "epochs: 7\t cost: 0.0343 \t accuracy: 0.7532\n",
      "epochs: 8\t cost: 0.0250 \t accuracy: 0.7540\n",
      "epochs: 9\t cost: 0.0223 \t accuracy: 0.7538\n",
      "epochs: 10\t cost: 0.0195 \t accuracy: 0.7593\n",
      "epochs: 11\t cost: 0.0141 \t accuracy: 0.7607\n",
      "epochs: 12\t cost: 0.0127 \t accuracy: 0.7610\n",
      "epochs: 13\t cost: 0.0116 \t accuracy: 0.7635\n",
      "epochs: 14\t cost: 0.0097 \t accuracy: 0.7635\n",
      "epochs: 15\t cost: 0.0110 \t accuracy: 0.7644\n",
      "epochs: 16\t cost: 0.0082 \t accuracy: 0.7672\n",
      "epochs: 17\t cost: 0.0084 \t accuracy: 0.7674\n",
      "epochs: 18\t cost: 0.0078 \t accuracy: 0.7705\n",
      "epochs: 19\t cost: 0.0076 \t accuracy: 0.7674\n",
      "epochs: 20\t cost: 0.0065 \t accuracy: 0.7683\n",
      "\n",
      "Accuracy: 0.7708\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training with Neurons: 500, Learning Rate: 0.0001\n",
      "------------------------------------------------------------\n",
      "epochs: 1\t cost: 0.7755 \t accuracy: 0.6316\n",
      "epochs: 2\t cost: 0.2999 \t accuracy: 0.7128\n",
      "epochs: 3\t cost: 0.1288 \t accuracy: 0.7451\n",
      "epochs: 4\t cost: 0.0819 \t accuracy: 0.7418\n",
      "epochs: 5\t cost: 0.0511 \t accuracy: 0.7518\n",
      "epochs: 6\t cost: 0.0348 \t accuracy: 0.7577\n",
      "epochs: 7\t cost: 0.0291 \t accuracy: 0.7560\n",
      "epochs: 8\t cost: 0.0199 \t accuracy: 0.7624\n",
      "epochs: 9\t cost: 0.0212 \t accuracy: 0.7613\n",
      "epochs: 10\t cost: 0.0150 \t accuracy: 0.7658\n",
      "epochs: 11\t cost: 0.0134 \t accuracy: 0.7638\n",
      "epochs: 12\t cost: 0.0110 \t accuracy: 0.7660\n",
      "epochs: 13\t cost: 0.0102 \t accuracy: 0.7694\n",
      "epochs: 14\t cost: 0.0108 \t accuracy: 0.7683\n",
      "epochs: 15\t cost: 0.0087 \t accuracy: 0.7677\n",
      "epochs: 16\t cost: 0.0071 \t accuracy: 0.7674\n",
      "epochs: 17\t cost: 0.0078 \t accuracy: 0.7727\n",
      "epochs: 18\t cost: 0.0068 \t accuracy: 0.7691\n",
      "epochs: 19\t cost: 0.0073 \t accuracy: 0.7691\n",
      "epochs: 20\t cost: 0.0070 \t accuracy: 0.7691\n",
      "\n",
      "Accuracy: 0.7836\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training with Neurons: 700, Learning Rate: 0.0001\n",
      "------------------------------------------------------------\n",
      "epochs: 1\t cost: 0.6491 \t accuracy: 0.6729\n",
      "epochs: 2\t cost: 0.2533 \t accuracy: 0.7412\n",
      "epochs: 3\t cost: 0.1106 \t accuracy: 0.7571\n",
      "epochs: 4\t cost: 0.0618 \t accuracy: 0.7803\n",
      "epochs: 5\t cost: 0.0432 \t accuracy: 0.7800\n",
      "epochs: 6\t cost: 0.0364 \t accuracy: 0.7844\n",
      "epochs: 7\t cost: 0.0244 \t accuracy: 0.7797\n",
      "epochs: 8\t cost: 0.0226 \t accuracy: 0.7833\n",
      "epochs: 9\t cost: 0.0184 \t accuracy: 0.7856\n",
      "epochs: 10\t cost: 0.0151 \t accuracy: 0.7822\n",
      "epochs: 11\t cost: 0.0127 \t accuracy: 0.7833\n",
      "epochs: 12\t cost: 0.0095 \t accuracy: 0.7833\n",
      "epochs: 13\t cost: 0.0089 \t accuracy: 0.7828\n",
      "epochs: 14\t cost: 0.0087 \t accuracy: 0.7844\n",
      "epochs: 15\t cost: 0.0084 \t accuracy: 0.7853\n",
      "epochs: 16\t cost: 0.0081 \t accuracy: 0.7847\n",
      "epochs: 17\t cost: 0.0063 \t accuracy: 0.7853\n",
      "epochs: 18\t cost: 0.0061 \t accuracy: 0.7844\n",
      "epochs: 19\t cost: 0.0053 \t accuracy: 0.7864\n",
      "epochs: 20\t cost: 0.0058 \t accuracy: 0.7839\n",
      "\n",
      "Accuracy: 0.7934\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best Model Accuracy: 0.8224\n"
     ]
    }
   ],
   "source": [
    "# Store models' accuracy for different configurations\n",
    "models_accuracy = {}\n",
    "\n",
    "# Initialize the best model and its accuracy\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "\n",
    "# Train different model configurations\n",
    "for lr in LEARNING_RATES:\n",
    "    for neuron_count in NEURONS:\n",
    "        print('\\n' + '-' * 60)\n",
    "        print(f'Training with Neurons: {neuron_count}, Learning Rate: {lr}')\n",
    "        print('-' * 60)\n",
    "        \n",
    "        # Create the model\n",
    "        model = Sequential_layers([\n",
    "            Linear(INPUT_DIM, neuron_count), \n",
    "            ReLU(), \n",
    "            Linear(neuron_count, neuron_count),\n",
    "            ReLU(), \n",
    "            Linear(neuron_count, neuron_count),\n",
    "            ReLU(), \n",
    "            Linear(neuron_count, OUTPUT_DIM)\n",
    "        ])\n",
    "        \n",
    "        # Train the model\n",
    "        trained_model = train(model, EPOCHS, BATCH_SIZE, lr)\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        test_acc = accuracy(x_test, y_test, BATCH_SIZE, model)\n",
    "        print(f'\\nAccuracy: {test_acc:.4f}')\n",
    "        \n",
    "        models_accuracy[(lr, neuron_count)] = test_acc\n",
    "        \n",
    "        # Update the best model if the current model is better\n",
    "        if test_acc > best_accuracy:\n",
    "            best_accuracy = test_acc\n",
    "            best_model = trained_model\n",
    "\n",
    "# Print the best model's accuracy\n",
    "print('\\n' + '-' * 60)\n",
    "print(f\"\\nBest Model Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your model on Random data from your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value is: m, real value is:m\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test[idx].reshape(28,28))\n",
    "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
    "\n",
    "print(f'Predicted value is: {alphabet[pred]}, real value is:{alphabet[y_test[idx][0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
